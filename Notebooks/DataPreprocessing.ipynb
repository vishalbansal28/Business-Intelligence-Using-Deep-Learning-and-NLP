{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7PnurdPCrCoJ3b1OdQT7B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivllnv/CPE313-Final-Project/blob/main/Notebooks/DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "r1DOdk82FljE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX7Pwbr2Fkny"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/Dataset/Yelp_AcademicDataset/yelp_academic_dataset_review.json\"\n",
        "\n",
        "review = pd.read_json(file_path,\n",
        "                     lines=True,\n",
        "                     chunksize=100000)\n",
        "\n",
        "for r in review:\n",
        "    subset = r\n",
        "    break\n",
        "\n",
        "df = pd.DataFrame(subset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "EsfX37ZSFodG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "h3_U5bpiFxSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "wxc517j-F8Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "5024Qs6eFyhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "h-9vqbcGF1G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sentence):\n",
        "  sentence=str(sentence)\n",
        "  sentence = sentence.lower()\n",
        "  sentence=sentence.replace('{html}',\"\")\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', sentence)\n",
        "  rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "  rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(rem_num)\n",
        "  filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "  stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "  lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "  return \" \".join(filtered_words)"
      ],
      "metadata": {
        "id": "kZKRrAsmFw1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleanText']=df['text'].map(lambda s:preprocess(s))"
      ],
      "metadata": {
        "id": "VIboGuVnF4xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('dataset_finals.csv',\n",
        "          header=['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date', 'cleanText'],\n",
        "          index=False)"
      ],
      "metadata": {
        "id": "5O4PiPWdF6Sh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}